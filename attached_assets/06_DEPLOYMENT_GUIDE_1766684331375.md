# B2T Voice Platform - Deployment Guide

## Overview
This guide provides step-by-step instructions for deploying the B2T Voice platform in production.

## Prerequisites

### System Requirements
- **Kubernetes cluster** (1.24+) or **Docker Swarm**
- **PostgreSQL** 15+ (for structured data)
- **MongoDB** 6.0+ (for conversation logs)
- **Redis** 7+ (for caching and sessions)
- **RabbitMQ** or **Kafka** (for message queuing)
- **Elasticsearch** 8+ (for search and analytics)
- **InfluxDB** 2.0+ (for time-series metrics)

### Development Tools
- **Python** 3.11+
- **Node.js** 18+
- **Docker** 24+
- **kubectl** (for Kubernetes)
- **Helm** 3+ (for K8s package management)

## Infrastructure Setup

### 1. Kubernetes Deployment

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: b2t-voice

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: b2t-config
  namespace: b2t-voice
data:
  POSTGRES_HOST: "postgres-service"
  POSTGRES_PORT: "5432"
  POSTGRES_DB: "b2t_voice"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  MONGODB_HOST: "mongodb-service"
  MONGODB_PORT: "27017"
  RABBITMQ_HOST: "rabbitmq-service"
  ENVIRONMENT: "production"

---
# k8s/secrets.yaml (use sealed-secrets in production)
apiVersion: v1
kind: Secret
metadata:
  name: b2t-secrets
  namespace: b2t-voice
type: Opaque
stringData:
  POSTGRES_PASSWORD: "changeme"
  REDIS_PASSWORD: "changeme"
  MONGODB_PASSWORD: "changeme"
  JWT_SECRET: "changeme"
  OPENAI_API_KEY: "sk-..."
  ANTHROPIC_API_KEY: "sk-..."

---
# k8s/deployments/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: b2t-api
  namespace: b2t-voice
spec:
  replicas: 3
  selector:
    matchLabels:
      app: b2t-api
  template:
    metadata:
      labels:
        app: b2t-api
    spec:
      containers:
      - name: api
        image: b2t-voice/api:latest
        ports:
        - containerPort: 8000
        envFrom:
        - configMapRef:
            name: b2t-config
        - secretRef:
            name: b2t-secrets
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/services/api-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: b2t-api-service
  namespace: b2t-voice
spec:
  selector:
    app: b2t-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: b2t-ingress
  namespace: b2t-voice
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.b2tvoice.com
    secretName: b2t-tls
  rules:
  - host: api.b2tvoice.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: b2t-api-service
            port:
              number: 80
```

### 2. Docker Compose (Development)

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: b2t_voice
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongodb:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: mongo
      MONGO_INITDB_ROOT_PASSWORD: mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --requirepass redis

  rabbitmq:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_DEFAULT_USER: rabbitmq
      RABBITMQ_DEFAULT_PASS: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"

  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  influxdb:
    image: influxdb:2.7
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: adminpassword
      DOCKER_INFLUXDB_INIT_ORG: b2t
      DOCKER_INFLUXDB_INIT_BUCKET: metrics
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2

  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    depends_on:
      - postgres
      - redis
      - mongodb
      - rabbitmq
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/b2t_voice
      REDIS_URL: redis://:redis@redis:6379
      MONGODB_URL: mongodb://mongo:mongo@mongodb:27017
      RABBITMQ_URL: amqp://rabbitmq:rabbitmq@rabbitmq:5672
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      - api
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      REACT_APP_API_URL: http://localhost:8000

volumes:
  postgres_data:
  mongo_data:
  es_data:
  influxdb_data:
```

### 3. Application Dockerfiles

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Run migrations and start server
CMD ["sh", "-c", "alembic upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000"]

# frontend/Dockerfile
FROM node:18-alpine

WORKDIR /app

# Install dependencies
COPY package.json package-lock.json ./
RUN npm ci

# Copy application code
COPY . .

# Build for production
RUN npm run build

# Serve with nginx
FROM nginx:alpine
COPY --from=0 /app/build /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

## Database Setup

### 1. PostgreSQL Schema

```sql
-- migrations/001_initial_schema.sql

CREATE TABLE agents (
    agent_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    template_id VARCHAR(50),
    configuration JSONB,
    status VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE workflows (
    workflow_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    trigger_intent VARCHAR(100),
    steps JSONB,
    agent_id VARCHAR(50) REFERENCES agents(agent_id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE integrations (
    integration_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50),
    config JSONB,
    agent_id VARCHAR(50) REFERENCES agents(agent_id),
    enabled BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE users (
    user_id VARCHAR(50) PRIMARY KEY,
    email VARCHAR(255) UNIQUE,
    name VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE sessions (
    session_id VARCHAR(50) PRIMARY KEY,
    user_id VARCHAR(50) REFERENCES users(user_id),
    agent_id VARCHAR(50) REFERENCES agents(agent_id),
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ended_at TIMESTAMP,
    metadata JSONB
);

CREATE INDEX idx_agents_status ON agents(status);
CREATE INDEX idx_sessions_user ON sessions(user_id);
CREATE INDEX idx_sessions_agent ON sessions(agent_id);
```

### 2. MongoDB Collections

```javascript
// MongoDB setup script

db.createCollection("conversations", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["session_id", "messages"],
      properties: {
        session_id: { bsonType: "string" },
        user_id: { bsonType: "string" },
        agent_id: { bsonType: "string" },
        messages: {
          bsonType: "array",
          items: {
            bsonType: "object",
            required: ["role", "content", "timestamp"],
            properties: {
              role: { enum: ["user", "assistant"] },
              content: { bsonType: "string" },
              timestamp: { bsonType: "date" },
              metadata: { bsonType: "object" }
            }
          }
        },
        metadata: { bsonType: "object" }
      }
    }
  }
});

db.createCollection("analytics_events", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["event_type", "session_id", "timestamp"],
      properties: {
        event_id: { bsonType: "string" },
        event_type: { bsonType: "string" },
        session_id: { bsonType: "string" },
        user_id: { bsonType: "string" },
        agent_id: { bsonType: "string" },
        timestamp: { bsonType: "date" },
        data: { bsonType: "object" }
      }
    }
  }
});

// Create indexes
db.conversations.createIndex({ session_id: 1 });
db.conversations.createIndex({ user_id: 1 });
db.conversations.createIndex({ agent_id: 1 });
db.conversations.createIndex({ "messages.timestamp": -1 });

db.analytics_events.createIndex({ session_id: 1 });
db.analytics_events.createIndex({ event_type: 1 });
db.analytics_events.createIndex({ timestamp: -1 });
db.analytics_events.createIndex({ agent_id: 1, timestamp: -1 });
```

## Deployment Steps

### Step 1: Build Docker Images

```bash
# Build backend
cd backend
docker build -t b2t-voice/api:latest .

# Build frontend
cd ../frontend
docker build -t b2t-voice/frontend:latest .

# Push to registry
docker push b2t-voice/api:latest
docker push b2t-voice/frontend:latest
```

### Step 2: Deploy to Kubernetes

```bash
# Create namespace
kubectl apply -f k8s/namespace.yaml

# Apply configurations
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml

# Deploy databases (or use managed services)
helm install postgres bitnami/postgresql -n b2t-voice
helm install mongodb bitnami/mongodb -n b2t-voice
helm install redis bitnami/redis -n b2t-voice
helm install rabbitmq bitnami/rabbitmq -n b2t-voice

# Deploy application
kubectl apply -f k8s/deployments/
kubectl apply -f k8s/services/
kubectl apply -f k8s/ingress.yaml

# Check status
kubectl get pods -n b2t-voice
kubectl logs -f deployment/b2t-api -n b2t-voice
```

### Step 3: Initialize Database

```bash
# Run migrations
kubectl exec -it deployment/b2t-api -n b2t-voice -- alembic upgrade head

# Seed initial data
kubectl exec -it deployment/b2t-api -n b2t-voice -- python scripts/seed_data.py
```

### Step 4: Configure Monitoring

```bash
# Install Prometheus & Grafana
helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring --create-namespace

# Install Jaeger for tracing
helm install jaeger jaegertracing/jaeger -n monitoring

# Configure alerts
kubectl apply -f monitoring/alerts.yaml
```

## Configuration Management

### Environment Variables

```bash
# .env.production
DATABASE_URL=postgresql://user:pass@postgres:5432/b2t_voice
REDIS_URL=redis://:password@redis:6379/0
MONGODB_URL=mongodb://user:pass@mongodb:27017/b2t_voice
RABBITMQ_URL=amqp://user:pass@rabbitmq:5672

# API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-...
GOOGLE_CLOUD_API_KEY=...

# Security
JWT_SECRET=your-secret-key
ENCRYPTION_KEY=your-encryption-key

# Features
ENABLE_WEB_SEARCH=true
ENABLE_VOICE=true
ENABLE_ANALYTICS=true
```

## Monitoring & Observability

### Grafana Dashboards

```json
{
  "dashboard": {
    "title": "B2T Voice Platform",
    "panels": [
      {
        "title": "API Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "NLU Confidence",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(nlu_confidence_bucket[5m]))"
          }
        ]
      },
      {
        "title": "Conversation Success Rate",
        "targets": [
          {
            "expr": "rate(conversations_completed_total[5m]) / rate(conversations_started_total[5m])"
          }
        ]
      }
    ]
  }
}
```

## Security Checklist

- [ ] Enable HTTPS/TLS everywhere
- [ ] Implement API rate limiting
- [ ] Use secrets management (HashiCorp Vault, AWS Secrets Manager)
- [ ] Enable RBAC in Kubernetes
- [ ] Implement audit logging
- [ ] Regular security scanning (Snyk, Trivy)
- [ ] Enable network policies
- [ ] Implement DDoS protection
- [ ] Regular backup and disaster recovery testing
- [ ] PII data encryption at rest and in transit

## Performance Optimization

1. **Caching Strategy**
   - Redis for session data (TTL: 1 hour)
   - CDN for static assets
   - API response caching (5 minutes for read-heavy endpoints)

2. **Database Optimization**
   - Connection pooling (min: 5, max: 20)
   - Read replicas for analytics queries
   - Indexes on frequently queried fields

3. **Horizontal Scaling**
   - Auto-scaling: min 3, max 10 pods
   - CPU threshold: 70%
   - Memory threshold: 80%

## Maintenance

### Regular Tasks

```bash
# Weekly
- Review and optimize database queries
- Check error logs and fix issues
- Update dependencies

# Monthly
- Security patches
- Performance review
- Backup verification
- Cost optimization

# Quarterly
- Disaster recovery drill
- Architecture review
- Capacity planning
```

This deployment guide provides a production-ready setup for the B2T Voice platform with comprehensive monitoring, security, and scalability.
